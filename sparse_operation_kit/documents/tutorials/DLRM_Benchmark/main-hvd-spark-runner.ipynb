{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a25bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import horovod.spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9200e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--lr'], dest='lr', nargs=None, const=None, default=24.0, type=<class 'float'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--data_dir\", type=str)\n",
    "parser.add_argument(\"--global_batch_size\", type=int)\n",
    "parser.add_argument(\"--amp\", action=\"store_true\", help=\"use auto mixed precision\")\n",
    "parser.add_argument(\"--xla\", action=\"store_true\", help=\"enable xla of tensorflow\")\n",
    "parser.add_argument(\n",
    "    \"--compress\",\n",
    "    action=\"store_true\",\n",
    "    help=\"use tf.unique/tf.gather to compress/decompress embedding keys\",\n",
    ")\n",
    "parser.add_argument(\"--custom_interact\", action=\"store_true\", help=\"use custom interact op\")\n",
    "parser.add_argument(\n",
    "    \"--eval_in_last\", action=\"store_true\", help=\"evaluate only after the last iteration\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--use_synthetic_dataset\", action=\"store_true\", help=\"use synthetic dataset for profiling\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--use_splited_dataset\",\n",
    "    action=\"store_true\",\n",
    "    help=\"categories features were splited into different binary files\",\n",
    ")\n",
    "parser.add_argument(\"--early_stop\", type=int, default=-1)\n",
    "parser.add_argument(\"--epochs\", type=int, default=1)\n",
    "parser.add_argument(\"--lr\", type=float, default=24.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "467a3e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] args: Namespace(amp=False, compress=False, custom_interact=False, data_dir=None, early_stop=-1, epochs=100, eval_in_last=False, global_batch_size=512, lr=24.0, lr_schedule_steps=[297000, 5326020, 2999376], num_proc=2, use_splited_dataset=False, use_synthetic_dataset=True, xla=False)\n"
     ]
    }
   ],
   "source": [
    "local_batch_size = 1 << 8\n",
    "num_proc = 2\n",
    "args = parser.parse_args([\"--epochs=100\",f\"--global_batch_size={num_proc * local_batch_size}\",\"--use_synthetic_dataset\"])\n",
    "args.num_proc = num_proc\n",
    "args.lr_schedule_steps = [\n",
    "    int(2750 * 55296 / args.global_batch_size),\n",
    "    int(49315 * 55296 / args.global_batch_size),\n",
    "    int(27772 * 55296 / args.global_batch_size),\n",
    "]\n",
    "args.num_proc = 2\n",
    "print(\"[Info] args:\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "493e1977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://127.0.0.1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://127.0.0.1:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0108108610>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf4d9ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(args):\n",
    "    import os\n",
    "    from horovod.spark.task import get_available_devices\n",
    "    \n",
    "    if args.xla:\n",
    "        os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=fusible\"\n",
    "    \n",
    "    gpus = get_available_devices()\n",
    "    print(\"gpus: \" + str(gpus))\n",
    "    if gpus:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = gpus[0]\n",
    "        \n",
    "    import sparse_operation_kit as sok\n",
    "    import horovod.tensorflow as hvd\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    from dataset import BinaryDataset, SplitedBinaryDataset, SyntheticDataset\n",
    "    from model import DLRM\n",
    "    from trainer import Trainer\n",
    "    import json\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "        \n",
    "    if args.amp:\n",
    "        print(\"[Info] use amp mode\")\n",
    "        policy = tf.keras.mixed_precision.Policy(\"mixed_float16\")\n",
    "        tf.keras.mixed_precision.set_global_policy(policy)\n",
    "\n",
    "    hvd.init()\n",
    "\n",
    "    global_batch_size = args.global_batch_size\n",
    "    sok.Init(global_batch_size=global_batch_size)\n",
    "    \n",
    "    if not (args.use_synthetic_dataset or args.data_dir is None):\n",
    "        with open(os.path.join(args.data_dir, \"train/metadata.json\"), \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    else:\n",
    "        vocab_sizes = [\n",
    "            39884406,\n",
    "            39043,\n",
    "            17289,\n",
    "            7420,\n",
    "            20263,\n",
    "            3,\n",
    "            7120,\n",
    "            1543,\n",
    "            63,\n",
    "            38532951,\n",
    "            2953546,\n",
    "            403346,\n",
    "            10,\n",
    "            2208,\n",
    "            11938,\n",
    "            155,\n",
    "            4,\n",
    "            976,\n",
    "            14,\n",
    "            39979771,\n",
    "            25641295,\n",
    "            39664984,\n",
    "            585935,\n",
    "            12972,\n",
    "            108,\n",
    "            36,\n",
    "        ]\n",
    "        metadata = {\"vocab_sizes\": vocab_sizes}\n",
    "    print(metadata)\n",
    "    embedding_vec_size=64\n",
    "    model = DLRM(\n",
    "        metadata[\"vocab_sizes\"],\n",
    "        num_dense_features=13,\n",
    "        #embedding_vec_size=128,\n",
    "        embedding_vec_size=embedding_vec_size,\n",
    "        bottom_stack_units=[512, 256, embedding_vec_size],\n",
    "        top_stack_units=[1024, 1024, 512, 256, 1],\n",
    "        num_gpus=hvd.size(),\n",
    "        use_cuda_interact=args.custom_interact,\n",
    "        compress=args.compress,\n",
    "    )\n",
    "\n",
    "    if args.use_synthetic_dataset or args.data_dir is None:\n",
    "        print(\"[Info] Using synthetic dataset\")\n",
    "\n",
    "        dataset = SyntheticDataset(\n",
    "            batch_size=global_batch_size // hvd.size(),\n",
    "            num_iterations=args.early_stop if args.early_stop > 0 else 30,\n",
    "            vocab_sizes=metadata[\"vocab_sizes\"],\n",
    "            prefetch=20,\n",
    "        )\n",
    "        test_dataset = SyntheticDataset(\n",
    "            batch_size=global_batch_size // hvd.size(),\n",
    "            num_iterations=args.early_stop if args.early_stop > 0 else 30,\n",
    "            vocab_sizes=metadata[\"vocab_sizes\"],\n",
    "            prefetch=20,\n",
    "        )\n",
    "    elif args.use_splited_dataset:\n",
    "        print(\"[Info] Using splited dataset in %s\" % args.data_dir)\n",
    "        dataset = SplitedBinaryDataset(\n",
    "            os.path.join(args.data_dir, \"train/label.bin\"),\n",
    "            os.path.join(args.data_dir, \"train/dense.bin\"),\n",
    "            [os.path.join(args.data_dir, \"train/category_%d.bin\" % i) for i in range(26)],\n",
    "            metadata[\"vocab_sizes\"],\n",
    "            batch_size=global_batch_size // hvd.size(),\n",
    "            drop_last=True,\n",
    "            global_rank=hvd.rank(),\n",
    "            global_size=hvd.size(),\n",
    "            prefetch=20,\n",
    "        )\n",
    "        test_dataset = SplitedBinaryDataset(\n",
    "            os.path.join(args.data_dir, \"test/label.bin\"),\n",
    "            os.path.join(args.data_dir, \"test/dense.bin\"),\n",
    "            [os.path.join(args.data_dir, \"test/category_%d.bin\" % i) for i in range(26)],\n",
    "            metadata[\"vocab_sizes\"],\n",
    "            batch_size=global_batch_size // hvd.size(),\n",
    "            drop_last=False,\n",
    "            global_rank=hvd.rank(),\n",
    "            global_size=hvd.size(),\n",
    "            prefetch=20,\n",
    "        )\n",
    "    else:\n",
    "        print(\"[Info] Using dataset in %s\" % args.data_dir)\n",
    "        dtype = {\"int32\": np.int32, \"float32\": np.float32}\n",
    "        dataset_dir = args.data_dir\n",
    "        dataset = BinaryDataset(\n",
    "            os.path.join(dataset_dir, \"train/label.bin\"),\n",
    "            os.path.join(dataset_dir, \"train/dense.bin\"),\n",
    "            os.path.join(dataset_dir, \"train/category.bin\"),\n",
    "            batch_size=global_batch_size // hvd.size(),\n",
    "            drop_last=True,\n",
    "            global_rank=hvd.rank(),\n",
    "            global_size=hvd.size(),\n",
    "            prefetch=20,\n",
    "            label_raw_type=dtype[metadata[\"label_raw_type\"]],\n",
    "            dense_raw_type=dtype[metadata[\"dense_raw_type\"]],\n",
    "            category_raw_type=dtype[metadata[\"category_raw_type\"]],\n",
    "            log=metadata[\"dense_log\"],\n",
    "        )\n",
    "        test_dataset = BinaryDataset(\n",
    "            os.path.join(dataset_dir, \"test/label.bin\"),\n",
    "            os.path.join(dataset_dir, \"test/dense.bin\"),\n",
    "            os.path.join(dataset_dir, \"test/category.bin\"),\n",
    "            batch_size=global_batch_size // hvd.size(),\n",
    "            drop_last=False,\n",
    "            global_rank=hvd.rank(),\n",
    "            global_size=hvd.size(),\n",
    "            prefetch=20,\n",
    "            label_raw_type=dtype[metadata[\"label_raw_type\"]],\n",
    "            dense_raw_type=dtype[metadata[\"dense_raw_type\"]],\n",
    "            category_raw_type=dtype[metadata[\"category_raw_type\"]],\n",
    "            log=metadata[\"dense_log\"],\n",
    "        )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        dataset,\n",
    "        test_dataset,\n",
    "        auc_thresholds=8000,\n",
    "        base_lr=args.lr,\n",
    "        warmup_steps=args.lr_schedule_steps[0],\n",
    "        decay_start_step=args.lr_schedule_steps[1],\n",
    "        decay_steps=args.lr_schedule_steps[2],\n",
    "        amp=args.amp,\n",
    "    )\n",
    "\n",
    "    if args.eval_in_last:\n",
    "        trainer.train(\n",
    "            eval_interval=None, eval_in_last=True, early_stop=args.early_stop, epochs=args.epochs\n",
    "        )\n",
    "    else:\n",
    "        trainer.train(eval_in_last=False, early_stop=args.early_stop, epochs=args.epochs)\n",
    "\n",
    "    print(\"main time: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c2d3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    # Horovod: run training.\n",
    "    history = horovod.spark.run(train_fn,\n",
    "                                args=(args,),\n",
    "                                num_proc=args.num_proc,\n",
    "                                #extra_mpi_args='-mca btl_tcp_if_include enp134s0f0 -x NCCL_IB_GID_INDEX=3',\n",
    "                                #extra_mpi_args='--mca btl tcp,sm,self',\n",
    "                                stdout=sys.stdout,\n",
    "                                stderr=sys.stderr,\n",
    "                                verbose=2,\n",
    "                                nics={},\n",
    "                                prefix_output_with_timestamp=True,\n",
    "                                env=dict(os.environ))[0]\n",
    "\n",
    "    print(f'history: {history}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbfa8b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether extension tensorflow was built with MPI.\n",
      "Extension tensorflow was built with MPI.\n",
      "mpirun --allow-run-as-root --tag-output -np 2 -H 3ea7bbc82c43-a981c8275bef9425530e401853bc2659:2 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib --timestamp-output     -x BASH_ENV -x BAZELRC -x CLICOLOR -x CUBLAS_VERSION -x CUDA_CACHE_DISABLE -x CUDA_CUDA_LIBRARY -x CUDA_DRIVER_VERSION -x CUDA_HOME -x CUDA_PATH -x CUDA_VERSION -x CUDNN_VERSION -x CUFFT_VERSION -x CURAND_VERSION -x CUSOLVER_VERSION -x CUSPARSE_VERSION -x CUTENSOR_VERSION -x DALI_BUILD -x DALI_VERSION -x DEBIAN_FRONTEND -x DLPROF_VERSION -x ENV -x GDRCOPY_VERSION -x GIT_PAGER -x HOME -x HOSTNAME -x HPCX_VERSION -x JPY_PARENT_PID -x JUPYTER_PORT -x LC_ALL -x LD_LIBRARY_PATH -x LESSCLOSE -x LESSOPEN -x LIBRARY_PATH -x LS_COLORS -x MOFED_VERSION -x MPLBACKEND -x NCCL_VERSION -x NPP_VERSION -x NSIGHT_COMPUTE_VERSION -x NSIGHT_SYSTEMS_VERSION -x NVIDIA_BUILD_ID -x NVIDIA_DRIVER_CAPABILITIES -x NVIDIA_PRODUCT_NAME -x NVIDIA_REQUIRE_CUDA -x NVIDIA_TENSORFLOW_VERSION -x NVIDIA_VISIBLE_DEVICES -x NVJPEG_VERSION -x NVM_BIN -x NVM_CD_FLAGS -x NVM_DIR -x NVM_INC -x OLD_PYTHONSTARTUP -x OMPI_MCA_coll_hcoll_enable -x OPAL_PREFIX -x OPENMPI_VERSION -x OPENUCX_VERSION -x PAGER -x PATH -x PIP_DEFAULT_TIMEOUT -x PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION -x PWD -x PYDEVD_USE_FRAME_EVAL -x PYSPARK_DRIVER_PYTHON -x PYSPARK_DRIVER_PYTHON_OPTS -x PYSPARK_PYTHON -x PYSPARK_SUBMIT_ARGS -x PYTHONHASHSEED -x PYTHONIOENCODING -x PYTHONPATH -x PYTHONSTARTUP -x PYVER -x RDMACORE_VERSION -x SHELL -x SHLVL -x SPARK_AUTH_SOCKET_TIMEOUT -x SPARK_BUFFER_SIZE -x SPARK_CONF_DIR -x SPARK_ENV_LOADED -x SPARK_HOME -x SPARK_PUBLIC_DNS -x SPARK_SCALA_VERSION -x SPARK_URL -x SPARK_WORKER_INSTANCES -x SPARK_WORKER_OPTS -x SPARK_WORKER_WEBUI_PORT -x TENSORBOARD_DEBUGGER_PORT -x TENSORBOARD_PORT -x TENSORFLOW_VERSION -x TERM -x TF_AUTOTUNE_THRESHOLD -x TF_USE_CUDNN_BATCHNORM_SPATIAL_PERSISTENT -x TRTOSS_VERSION -x TRT_VERSION -x _CUDA_COMPAT_PATH -x _CUDA_COMPAT_STATUS -x _SPARK_CMD_USAGE  -x NCCL_DEBUG=INFO -mca plm_rsh_agent \"/usr/bin/python -m horovod.spark.driver.mpirun_rsh gAWVOgAAAAAAAAB9lCiMAmxvlF2UjAkxMjcuMC4wLjGUTYnchpRhjARldGgwlF2UjAoxNzIuMTcuMC4ylE2J3IaUYXUu gAWVygIAAAAAAACMI2hvcm92b2QucnVubmVyLmNvbW1vbi51dGlsLnNldHRpbmdzlIwIU2V0dGluZ3OUk5QpgZR9lCiMCG51bV9wcm9jlEsCjAd2ZXJib3NllEsCjAhzc2hfcG9ydJROjBFzc2hfaWRlbnRpdHlfZmlsZZROjA5leHRyYV9tcGlfYXJnc5ROjAh0Y3BfZmxhZ5ROjAxiaW5kaW5nX2FyZ3OUTowDa2V5lE6MDXN0YXJ0X3RpbWVvdXSUjCJob3Jvdm9kLnJ1bm5lci5jb21tb24udXRpbC50aW1lb3V0lIwHVGltZW91dJSTlCmBlH2UKIwIX3RpbWVvdXSUTVgCjAtfdGltZW91dF9hdJRHQdjM2rtypjuMCF9tZXNzYWdllFgOAQAAVGltZWQgb3V0IHdhaXRpbmcgZm9yIHthY3Rpdml0eX0uIFBsZWFzZSBjaGVjayB0aGF0IHlvdSBoYXZlIGVub3VnaCByZXNvdXJjZXMgdG8gcnVuIGFsbCBIb3Jvdm9kIHByb2Nlc3Nlcy4gRWFjaCBIb3Jvdm9kIHByb2Nlc3MgcnVucyBpbiBhIFNwYXJrIHRhc2suIFlvdSBtYXkgbmVlZCB0byBpbmNyZWFzZSB0aGUgc3RhcnRfdGltZW91dCBwYXJhbWV0ZXIgdG8gYSBsYXJnZXIgdmFsdWUgaWYgeW91ciBTcGFyayByZXNvdXJjZXMgYXJlIGFsbG9jYXRlZCBvbi1kZW1hbmQulHVijA9vdXRwdXRfZmlsZW5hbWWUTowNcnVuX2Z1bmNfbW9kZZSIjARuaWNzlH2UjAdlbGFzdGljlImMHHByZWZpeF9vdXRwdXRfd2l0aF90aW1lc3RhbXCUiIwFaG9zdHOUjC8zZWE3YmJjODJjNDMtYTk4MWM4Mjc1YmVmOTQyNTUzMGU0MDE4NTNiYzI2NTk6MpR1Yi4=\" /usr/bin/python -m horovod.spark.task.mpirun_exec_fn gAWVOgAAAAAAAAB9lCiMAmxvlF2UjAkxMjcuMC4wLjGUTYnchpRhjARldGgwlF2UjAoxNzIuMTcuMC4ylE2J3IaUYXUu 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\n",
      "Tue Sep 27 21:18:22 2022[1,1]<stdout>:Changing cwd from /HugeCTR/sparse_operation_kit/documents/tutorials/DLRM_Benchmark to /usr/local/lib/python3.8/dist-packages/pyspark/work/app-20220927211802-0004/0\n",
      "Tue Sep 27 21:18:22 2022[1,0]<stdout>:Changing cwd from /HugeCTR/sparse_operation_kit/documents/tutorials/DLRM_Benchmark to /usr/local/lib/python3.8/dist-packages/pyspark/work/app-20220927211802-0004/0\n",
      "Tue Sep 27 21:18:22 2022[1,1]<stdout>:gpus: ['1']\n",
      "Tue Sep 27 21:18:22 2022[1,1]<stdout>:[INFO]: sparse_operation_kit is imported\n",
      "Tue Sep 27 21:18:22 2022[1,0]<stdout>:gpus: ['0']\n",
      "Tue Sep 27 21:18:22 2022[1,0]<stdout>:[INFO]: sparse_operation_kit is imported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tue Sep 27 21:18:25 2022[1,0]<stderr>:2022-09-27 21:18:25.288984: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "Tue Sep 27 21:18:25 2022[1,0]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Tue Sep 27 21:18:25 2022[1,1]<stderr>:2022-09-27 21:18:25.355467: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "Tue Sep 27 21:18:25 2022[1,1]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Tue Sep 27 21:18:25 2022[1,0]<stderr>:2022-09-27 21:18:25.985843: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "Tue Sep 27 21:18:25 2022[1,0]<stderr>:2022-09-27 21:18:25.985924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30998 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stderr>:2022-09-27 21:18:26.038724: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stderr>:2022-09-27 21:18:26.038799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30998 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB-H, pci bus id: 0000:36:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Bootstrap : Using eth0:172.17.0.2<0>\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v5 symbol.\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v5 symbol.\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO P2P plugin IBext\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO NET/IB : No device found.\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO NET/IB : No device found.\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO NET/Socket : Using [0]eth0:172.17.0.2<0>\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Using network Socket\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:2022-09-27 21:18:26.313506: I sparse_operation_kit/kit_cc/kit_cc_infra/src/resources/manager.cc:107] Mapping from local_replica_id to device_id:\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:2022-09-27 21:18:26Tue Sep 27 21:18:26 2022[1,0]<stdout>:2022-09-27 21:18:26.313506: I sparse_operation_kit/kit_cc/kit_cc_infra/src/resources/manager.cc:107] Mapping from local_replica_id to device_id:\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:2022-09-27 21:18:26.313506: I sparse_operation_kit/kit_cc/kit_cc_infra/src/resources/manager.cc:109] 0 -> 0\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:2022-09-27 21:18:26.313506: I Tue Sep 27 21:18:26 2022[1,1]<stdout>:.313506: I sparse_operation_kit/kit_cc/kit_cc_infra/src/resources/manager.cc:109] 0 -> 0\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:2022-09-27 21:18:26.313506: I sparse_operation_kit/kit_cc/kit_cc_infra/src/resources/manager.cc:84] Global seed is 873275489\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:2022-09-27 21:18:26.313506: I sparse_operation_kit/kit_cc/kit_cc_infra/src/resources/manager.cc:85] Local GPU Count: 1\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:sparse_operation_kit/kit_cc/kit_cc_infra/src/resources/manager.cc:84] Global seed is 873275489\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:2022-09-27 21:18:26.313506: I sparse_operation_kit/kit_cc/kit_cc_infra/src/resources/manager.cc:85] Local GPU Count: 1\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:2022-09-27 21:18:26.313506: I sparse_operation_kit/kit_cc/kit_cc_infra/src/resources/manager.cc:86] Global GPU Count: 2\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:2022-09-27 21:18:26.313506: I sparse_operation_kit/kit_cc/kit_cc_infra/src/resources/manager.cc:86] Global GPU Count: 2\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:2022-09-27Tue Sep 27 21:18:26 2022[1,1]<stdout>:2022-09-27 21:Tue Sep 27 21:18:26 2022[1,0]<stdout>: 21:18:26.313506: I Tue Sep 27 21:18:26 2022[1,1]<stdout>:18:26.313506: I sparse_operation_kit/kit_cc/kit_cc_infra/src/resources/manager.cc:127] Global Replica Id: 1; Local Replica Id: 0\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:sparse_operation_kit/kit_cc/kit_cc_infra/src/resources/manager.cc:127] Global Replica Id: 0; Local Replica Id: 0\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:NCCL version 2.12.9+cuda11.6\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Bootstrap : Using eth0:172.17.0.2<0>\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v5 symbol.\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v5 symbol.\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO P2P plugin IBext\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO NET/IB : No device found.\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO NET/IB : No device found.\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO NET/Socket : Using [0]eth0:172.17.0.2<0>\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Using network Socket\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Setting affinity for GPU 1 to ff,ffff0000,00ffffff\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 00/12 :    0   1\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 01/12 :    0   1\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 02/12 :    0   1\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 03/12 :    0   1\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 04/12 :    0   1\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0 [8] -1/-1/-1->1->0 [9] -1/-1/-1->1->0 [10] -1/-1/-1->1->0 [11] -1/-1/-1->1->0\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 05/12 :    0   1\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 06/12 :    0   1\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 07/12 :    0   1\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 08/12 :    0   1\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 09/12 :    0   1\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 10/12 :    0   1\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 11/12 :    0   1\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Channel 00 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 00 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Channel 01 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 01 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Channel 02 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 02 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Channel 03 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 03 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Channel 04 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 04 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Channel 05 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 05 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Channel 06 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 06 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Channel 07 : 1[36000] -> 0[34000] via P2P/IPC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 07 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Channel 08 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 08 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Channel 09 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 09 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Channel 10 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 10 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Channel 11 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Channel 11 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Connected all rings\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO Connected all trees\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Connected all rings\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO Connected all trees\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO 12 coll channels, 16 p2p channels, 16 p2p channels per peer\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO 12 coll channels, 16 p2p channels, 16 p2p channels per peer\n",
      "Tue Sep 27 21:18:26 2022[1,1]<stdout>:3ea7bbc82c43:29030:29030 [0] NCCL INFO comm 0x1e0e4bc0 rank 1 nranks 2 cudaDev 0 busId 36000 - Init COMPLETE\n",
      "Tue Sep 27 21:18:26 2022[1,0]<stdout>:3ea7bbc82c43:29029:29029 [0] NCCL INFO comm 0x1dafac10 rank 0 nranks 2 cudaDev 0 busId 34000 - Init COMPLETE\n",
      "Tue Sep 27 21:18:27 2022[1,0]<stdout>:{'vocab_sizes': [39884406, 39043, 17289, 7420, 20263, 3, 7120, 1543, 63, 38532951, 2953546, 403346, 10, 2208, 11938, 155, 4, 976, 14, 39979771, 25641295, 39664984, 585935, 12972, 108, 36]}\n",
      "Tue Sep 27 21:18:27 2022[1,0]<stdout>:[Info] Total vocabulary size: 187767399\n",
      "Tue Sep 27 21:18:27 2022[1,0]<stdout>:2022-09-27 21:18:27.313507: I sparse_operation_kit/kit_cc/kit_cc_infra/src/parameters/raw_manager.cc:132] Created embedding variable whose name is EmbeddingVariable\n",
      "Tue Sep 27 21:18:27 2022[1,1]<stdout>:{'vocab_sizes': [39884406, 39043, 17289, 7420, 20263, 3, 7120, 1543, 63, 38532951, 2953546, 403346, 10, 2208, 11938, 155, 4, 976, 14, 39979771, 25641295, 39664984, 585935, 12972, 108, 36]}\n",
      "Tue Sep 27 21:18:27 2022[1,0]<stdout>:[Info] Using synthetic dataset\n",
      "Tue Sep 27 21:18:27 2022[1,1]<stdout>:[Info] Total vocabulary size: 187767399\n",
      "Tue Sep 27 21:18:27 2022[1,1]<stdout>:2022-09-27 21:18:27.313507: I sparse_operation_kit/kit_cc/kit_cc_infra/src/parameters/raw_manager.ccTue Sep 27 21:18:27 2022[1,1]<stdout>::132] Created embedding variable whose name is EmbeddingVariable\n",
      "Tue Sep 27 21:18:27 2022[1,1]<stdout>:[Info] Using synthetic dataset\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:2022-09-27 21:18:32.313512: I sparse_operation_kit/kit_cc/kit_cc_infra/src/parameters/raw_param.cc:120] Variable: EmbeddingVariable on global_replica_id: 0 start initialization\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:2022-09-27 21:18:32.313512: I sparse_operation_kit/kit_cc/kit_cc_infra/src/parameters/raw_param.cc:120] Variable: EmbeddingVariable on global_replica_id: 1 start initialization\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:2022-09-27 21:18:32.313512: I sparse_operation_kit/kit_cc/kit_cc_infra/src/parameters/raw_param.cc:137] Variable: EmbeddingVariable on global_replica_id: 0 initialization done.\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:2022-09-27 21Tue Sep 27 21:18:32 2022[1,0]<stdout>::18:32.313512: I Tue Sep 27 21:18:32 2022[1,0]<stdout>:sparse_operation_kit/kit_cc/kit_cc_infra/src/facade.cc:257] SparseOperationKit allocated internal memory.\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29499 [0] NCCL INFO Channel 00 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29499 [0] NCCL INFO Channel 01 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29499 [0] NCCL INFO Channel 02 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29499 [0] NCCL INFO Channel 03 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29499 [0] NCCL INFO Channel 04 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29499 [0] NCCL INFO Channel 05 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29499 [0] NCCL INFO Channel 06 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29499 [0] NCCL INFO Channel 07 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29499 [0] NCCL INFO Channel 08 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29499 [0] NCCL INFO Channel 09 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29499 [0] NCCL INFO Channel 10 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29499 [0] NCCL INFO Channel 11 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29499 [0] NCCL INFO Channel 12 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29499 [0] NCCL INFO Channel 13 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29499 [0] NCCL INFO Channel 14 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29499 [0] NCCL INFO Channel 15 : 0[34000] -> 1[36000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:2022-09-27 21:18:32.313512: I sparse_operation_kit/kit_cc/kit_cc_infra/src/parameters/raw_param.cc:137] Variable: EmbeddingVariable on global_replica_id: 1 initialization done.\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:2022-09-27 21:18:32.313512: I sparse_operation_kit/kit_cc/kit_cc_infra/src/facade.cc:257] SparseOperationKit allocated internal memory.\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:3ea7bbc82c43:29030:29500 [0] NCCL INFO Channel 00 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:3ea7bbc82c43:29030:29500 [0] NCCL INFO Channel 01 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:3ea7bbc82c43:29030:29500 [0] NCCL INFO Channel 02 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:3ea7bbc82c43:29030:29500 [0] NCCL INFO Channel 03 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:3ea7bbc82c43:29030:29500 [0] NCCL INFO Channel 04 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:3ea7bbc82c43:29030:29500 [0] NCCL INFO Channel 05 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:3ea7bbc82c43:29030:29500 [0] NCCL INFO Channel 06 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:3ea7bbc82c43:29030:29500 [0] NCCL INFO Channel 07 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:3ea7bbc82c43:29030:29500 [0] NCCL INFO Channel 08 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:3ea7bbc82c43:29030:29500 [0] NCCL INFO Channel 09 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:3ea7bbc82c43:29030:29500 [0] NCCL INFO Channel 10 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:3ea7bbc82c43:29030:29500 [0] NCCL INFO Channel 11 : 1[36000] -> 0[34000] via P2P/IPC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:3ea7bbc82c43:29030:29500 [0] NCCL INFO Channel 12 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:3ea7bbc82c43:29030:29500 [0] NCCL INFO Channel 13 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:3ea7bbc82c43:29030:29500 [0] NCCL INFO Channel 14 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:3ea7bbc82c43:29030:29500 [0] NCCL INFO Channel 15 : 1[36000] -> 0[34000] via P2P/IPC\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:3ea7bbc82c43:29029:29489 [0] NCCL INFO Launch mode Parallel\n",
      "Tue Sep 27 21:18:32 2022[1,1]<stdout>:Iteration 0 finished. The following log will be printed every 1000 iterations.\n",
      "Tue Sep 27 21:18:32 2022[1,0]<stdout>:Iteration 0 finished. The following log will be printed every 1000 iterations.\n",
      "Tue Sep 27 21:18:45 2022[1,0]<stdout>:Iteration:1000\tloss:0.692346\ttime:18.28s\tthroughput:0.03M\n",
      "Tue Sep 27 21:18:45 2022[1,1]<stdout>:Iteration:1000\tloss:0.689463\ttime:18.25s\tthroughput:0.03M\n",
      "Tue Sep 27 21:18:57 2022[1,1]<stdout>:Iteration:2000\tloss:0.692728\ttime:12.36s\tthroughput:0.04M\n",
      "Tue Sep 27 21:18:57 2022[1,0]<stdout>:Iteration:2000\tloss:0.693938\ttime:12.36s\tthroughput:0.04M\n",
      "Tue Sep 27 21:19:10 2022[1,0]<stdout>:total time: 43.08s, in 3000 iterations\n",
      "Tue Sep 27 21:19:10 2022[1,0]<stdout>:only training time: 43.08s, average: 14.36ms/iter, average throughput: 0.04M(12.36ms/iter)\n",
      "Tue Sep 27 21:19:10 2022[1,0]<stdout>:only evaluate time: 0.00s\n",
      "Tue Sep 27 21:19:10 2022[1,0]<stdout>:main time: 45.70s\n",
      "Tue Sep 27 21:19:10 2022[1,1]<stdout>:total time: 43.04s, in 3000 iterations\n",
      "Tue Sep 27 21:19:10 2022[1,1]<stdout>:only training time: 43.04s, average: 14.35ms/iter, average throughput: 0.04M(12.36ms/iter)\n",
      "Tue Sep 27 21:19:10 2022[1,1]<stdout>:only evaluate time: 0.00s\n",
      "Tue Sep 27 21:19:10 2022[1,1]<stdout>:main time: 45.66s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history: None\n"
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
